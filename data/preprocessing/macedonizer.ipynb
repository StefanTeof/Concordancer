{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at macedonizer/mk-roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at macedonizer/mk-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('macedonizer/mk-roberta-base')\n",
    "model = RobertaModel.from_pretrained('macedonizer/mk-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('../../preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_id                                           sentence\n",
      "0            1  Беше јасен и студен априлски ден а часовниците...\n",
      "1            2  Винстон Смит со брадата спуштена на градите за...\n",
      "2            3  Ходникот баздеше на варена зелка и на стари пр...\n",
      "3            4  На неговиот крај висеше постер во боја премног...\n",
      "4            5  Тој прикажуваше само едно огромно лице широко ...\n"
     ]
    }
   ],
   "source": [
    "# Create sentences\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "data['word'] = data['word'].astype(str)\n",
    "grouped_sentences = data.groupby('sentence_id')['word'].apply(lambda words: ' '.join(words)).reset_index(name='sentence')\n",
    "\n",
    "print(grouped_sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sentence_id                                     sentence_words\n",
      "0               1  [Беше, јасен, и, студен, априлски, ден, а, час...\n",
      "1               2  [Винстон, Смит, со, брадата, спуштена, на, гра...\n",
      "2               3  [Ходникот, баздеше, на, варена, зелка, и, на, ...\n",
      "3               4  [На, неговиот, крај, висеше, постер, во, боја,...\n",
      "4               5  [Тој, прикажуваше, само, едно, огромно, лице, ...\n",
      "...           ...                                                ...\n",
      "6785         6786  [Интересите, на, престижот, го, правеа, пожелн...\n",
      "6786         6787  [Разни, писатели, како, Шекспир, Милтон, Свифт...\n",
      "6787         6788  [Овие, преводи, беа, бавна, и, тешка, работа, ...\n",
      "6788         6789  [Постоеја, исто, така, големи, количества, од,...\n",
      "6789         6790  [Токму, за, да, се, обезбеди, време, за, прели...\n",
      "\n",
      "[6790 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_data = []\n",
    "\n",
    "data['word'] = data['word'].astype(str)\n",
    "\n",
    "grouped = data.groupby('sentence_id')['word'].apply(list).reset_index(name='sentence_words')\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# for _, row in grouped.head(20).iterrows():\n",
    "#     if i == 20:\n",
    "#         break\n",
    "#     sentence_id = row['sentence_id']\n",
    "#     words = row['sentence_words']\n",
    "#     sentence = \" \".join(words)\n",
    "    \n",
    "#     inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "    \n",
    "#     sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "#     word_embeddings = []\n",
    "#     current_word_index = 0\n",
    "#     subword_embeddings = []\n",
    "\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze().tolist())\n",
    "\n",
    "#     for token_index, token in enumerate(tokens):\n",
    "#         if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "#             continue  # Skip special tokens\n",
    "        \n",
    "#         # Check if the current token is a part of the current word\n",
    "#         if current_word_index < len(words) and words[current_word_index] in sentence[sentence.find(token):]:\n",
    "#             subword_embeddings.append(outputs.last_hidden_state[0, token_index, :].numpy())\n",
    "#             sentence = sentence.replace(token, \"\", 1)\n",
    "#         else:\n",
    "#             # Average the embeddings for the previous word\n",
    "#             if subword_embeddings:\n",
    "#                 word_embedding = np.mean(subword_embeddings, axis=0)\n",
    "#                 word_embeddings.append(word_embedding)\n",
    "#                 subword_embeddings = []  # Reset for the next word\n",
    "            \n",
    "#             current_word_index += 1  # Move to the next word\n",
    "            \n",
    "#             # Start collecting embeddings for the next word\n",
    "#             if current_word_index < len(words) and words[current_word_index] in sentence[sentence.find(token):]:\n",
    "#                 subword_embeddings.append(outputs.last_hidden_state[0, token_index, :].numpy())\n",
    "#                 sentence = sentence.replace(token, \"\", 1)\n",
    "    \n",
    "#     if subword_embeddings:\n",
    "#         word_embedding = np.mean(subword_embeddings, axis=0)\n",
    "#         word_embeddings.append(word_embedding)\n",
    "\n",
    "#     # Store the results\n",
    "#     word_ids = data[data['sentence_id'] == sentence_id]['word_id'].tolist()\n",
    "#     for word_id, word_embedding in zip(word_ids, word_embeddings):\n",
    "#         embeddings_data.append({\n",
    "#             'sentence_id': sentence_id,\n",
    "#             'word_id': word_id,\n",
    "#             'sentence_embedding': sentence_embedding.tolist(),\n",
    "#             'word_embedding': word_embedding.tolist()\n",
    "#         })\n",
    "        \n",
    "#     print(f\"Processing sentence_id {sentence_id} with {len(words)} words, generated {len(word_embeddings)} word embeddings.\")\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "# embeddings_df = pd.DataFrame(embeddings_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_data = []\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    sentence_id = row['sentence_id']\n",
    "    words = row['sentence_words']\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    \n",
    "    # Get all token embeddings\n",
    "    all_token_embeddings = outputs.last_hidden_state.squeeze().numpy()\n",
    "\n",
    "    # Initialize variables to track word formation from tokens\n",
    "    word_embeddings = []\n",
    "    token_idx = 1  # Start after [CLS]\n",
    "    for word in words:\n",
    "        # Accumulate token embeddings for the current word\n",
    "        token_embeddings = []\n",
    "        while token_idx < len(all_token_embeddings) - 1:  # Exclude [SEP]\n",
    "            token_embeddings.append(all_token_embeddings[token_idx])\n",
    "            token_text = tokenizer.decode(inputs['input_ids'][0, token_idx])\n",
    "            \n",
    "            # Condition to break the loop if this token marks the completion of the word\n",
    "            if token_text == word or tokenizer.decode(inputs['input_ids'][0, token_idx + 1]).startswith(' '):\n",
    "                token_idx += 1\n",
    "                break\n",
    "            token_idx += 1\n",
    "        \n",
    "        # Average the embeddings for the current word\n",
    "        if token_embeddings:\n",
    "            word_embeddings.append(np.mean(token_embeddings, axis=0))\n",
    "\n",
    "    word_ids = data[data['sentence_id'] == sentence_id]['word_id'].tolist()\n",
    "    for word_id, word_embedding in zip(word_ids, word_embeddings):\n",
    "        embeddings_data.append({\n",
    "            'sentence_id': sentence_id,\n",
    "            'word_id': word_id,\n",
    "            'sentence_embedding': sentence_embedding.tolist(),\n",
    "            'word_embedding': word_embedding.tolist()\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_embedding</th>\n",
       "      <th>word_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "      <td>[-0.19491949677467346, 0.3511471450328827, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "      <td>[-0.9175711870193481, 0.2979837656021118, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "      <td>[0.10833288729190826, -0.8593301177024841, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "      <td>[-1.1452068090438843, 0.9079347252845764, 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "      <td>[-0.4176254868507385, -0.5781083106994629, 2.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96057</th>\n",
       "      <td>6790</td>\n",
       "      <td>393</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "      <td>[0.12584611773490906, 1.1002881526947021, 0.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96058</th>\n",
       "      <td>6790</td>\n",
       "      <td>146</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "      <td>[2.428894519805908, -0.22653913497924805, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96059</th>\n",
       "      <td>6790</td>\n",
       "      <td>418</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "      <td>[2.666874408721924, -0.07137368619441986, 0.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96060</th>\n",
       "      <td>6790</td>\n",
       "      <td>4723</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "      <td>[1.2628905773162842, 0.04624204337596893, 0.66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96061</th>\n",
       "      <td>6790</td>\n",
       "      <td>949</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "      <td>[0.1627369076013565, 0.4012010991573334, 1.073...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96062 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  word_id  \\\n",
       "0                1        1   \n",
       "1                1        2   \n",
       "2                1        3   \n",
       "3                1        4   \n",
       "4                1        5   \n",
       "...            ...      ...   \n",
       "96057         6790      393   \n",
       "96058         6790      146   \n",
       "96059         6790      418   \n",
       "96060         6790     4723   \n",
       "96061         6790      949   \n",
       "\n",
       "                                      sentence_embedding  \\\n",
       "0      [-0.6169265508651733, 0.34044384956359863, 0.9...   \n",
       "1      [-0.6169265508651733, 0.34044384956359863, 0.9...   \n",
       "2      [-0.6169265508651733, 0.34044384956359863, 0.9...   \n",
       "3      [-0.6169265508651733, 0.34044384956359863, 0.9...   \n",
       "4      [-0.6169265508651733, 0.34044384956359863, 0.9...   \n",
       "...                                                  ...   \n",
       "96057  [0.3545113801956177, 0.2402992844581604, 0.740...   \n",
       "96058  [0.3545113801956177, 0.2402992844581604, 0.740...   \n",
       "96059  [0.3545113801956177, 0.2402992844581604, 0.740...   \n",
       "96060  [0.3545113801956177, 0.2402992844581604, 0.740...   \n",
       "96061  [0.3545113801956177, 0.2402992844581604, 0.740...   \n",
       "\n",
       "                                          word_embedding  \n",
       "0      [-0.19491949677467346, 0.3511471450328827, 1.0...  \n",
       "1      [-0.9175711870193481, 0.2979837656021118, -0.7...  \n",
       "2      [0.10833288729190826, -0.8593301177024841, 1.0...  \n",
       "3      [-1.1452068090438843, 0.9079347252845764, 0.48...  \n",
       "4      [-0.4176254868507385, -0.5781083106994629, 2.3...  \n",
       "...                                                  ...  \n",
       "96057  [0.12584611773490906, 1.1002881526947021, 0.75...  \n",
       "96058  [2.428894519805908, -0.22653913497924805, -0.0...  \n",
       "96059  [2.666874408721924, -0.07137368619441986, 0.47...  \n",
       "96060  [1.2628905773162842, 0.04624204337596893, 0.66...  \n",
       "96061  [0.1627369076013565, 0.4012010991573334, 1.073...  \n",
       "\n",
       "[96062 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_df.to_csv('../../embeddings_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_embeddings = embeddings_df[['word_id', 'sentence_id', 'word_embedding']].drop_duplicates(subset=['word_id'])\n",
    "\n",
    "df_word_embeddings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19491949677467346, 0.3511471450328827, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.9175711870193481, 0.2979837656021118, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.10833288729190826, -0.8593301177024841, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.1452068090438843, 0.9079347252845764, 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4176254868507385, -0.5781083106994629, 2.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15940</th>\n",
       "      <td>15941</td>\n",
       "      <td>6789</td>\n",
       "      <td>[0.25629445910453796, 0.03444233909249306, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15941</th>\n",
       "      <td>15942</td>\n",
       "      <td>6789</td>\n",
       "      <td>[-0.8041114807128906, 0.5293155312538147, 1.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15942</th>\n",
       "      <td>15943</td>\n",
       "      <td>6790</td>\n",
       "      <td>[-0.5313321352005005, 0.3916394114494324, 1.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15943</th>\n",
       "      <td>15944</td>\n",
       "      <td>6790</td>\n",
       "      <td>[-0.8071935176849365, 0.21436543762683868, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15944</th>\n",
       "      <td>15945</td>\n",
       "      <td>6790</td>\n",
       "      <td>[0.14871418476104736, -0.25419875979423523, 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15945 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_id  sentence_id                                     word_embedding\n",
       "0            1            1  [-0.19491949677467346, 0.3511471450328827, 1.0...\n",
       "1            2            1  [-0.9175711870193481, 0.2979837656021118, -0.7...\n",
       "2            3            1  [0.10833288729190826, -0.8593301177024841, 1.0...\n",
       "3            4            1  [-1.1452068090438843, 0.9079347252845764, 0.48...\n",
       "4            5            1  [-0.4176254868507385, -0.5781083106994629, 2.3...\n",
       "...        ...          ...                                                ...\n",
       "15940    15941         6789  [0.25629445910453796, 0.03444233909249306, 0.9...\n",
       "15941    15942         6789  [-0.8041114807128906, 0.5293155312538147, 1.09...\n",
       "15942    15943         6790  [-0.5313321352005005, 0.3916394114494324, 1.94...\n",
       "15943    15944         6790  [-0.8071935176849365, 0.21436543762683868, 0.8...\n",
       "15944    15945         6790  [0.14871418476104736, -0.25419875979423523, 1....\n",
       "\n",
       "[15945 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_embeddings = embeddings_df[['sentence_id', 'sentence_embedding']].drop_duplicates(subset=['sentence_id'])\n",
    "\n",
    "df_sentence_embeddings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.6169265508651733, 0.34044384956359863, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.31695646047592163, -0.06865434348583221, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.3484392464160919, -0.25705409049987793, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.048721782863140106, 0.7031247615814209, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.6102833151817322, 0.14064306020736694, 1.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785</th>\n",
       "      <td>6786</td>\n",
       "      <td>[0.2429082691669464, 0.22434552013874054, 1.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>6787</td>\n",
       "      <td>[0.47419729828834534, 0.10613614320755005, 1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>6788</td>\n",
       "      <td>[0.004281379748135805, 0.016001710668206215, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>6789</td>\n",
       "      <td>[0.47204872965812683, -0.029387781396508217, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>6790</td>\n",
       "      <td>[0.3545113801956177, 0.2402992844581604, 0.740...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6790 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id                                 sentence_embedding\n",
       "0               1  [-0.6169265508651733, 0.34044384956359863, 0.9...\n",
       "1               2  [-0.31695646047592163, -0.06865434348583221, 1...\n",
       "2               3  [-0.3484392464160919, -0.25705409049987793, 0....\n",
       "3               4  [-0.048721782863140106, 0.7031247615814209, 1....\n",
       "4               5  [0.6102833151817322, 0.14064306020736694, 1.02...\n",
       "...           ...                                                ...\n",
       "6785         6786  [0.2429082691669464, 0.22434552013874054, 1.11...\n",
       "6786         6787  [0.47419729828834534, 0.10613614320755005, 1.1...\n",
       "6787         6788  [0.004281379748135805, 0.016001710668206215, 1...\n",
       "6788         6789  [0.47204872965812683, -0.029387781396508217, 0...\n",
       "6789         6790  [0.3545113801956177, 0.2402992844581604, 0.740...\n",
       "\n",
       "[6790 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_embeddings.to_csv('../../word_embeddings.csv', index=False)\n",
    "df_sentence_embeddings.to_csv('../../unique_sentence_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
